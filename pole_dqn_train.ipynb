{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d664361d-e798-40e7-a287-8636016d0776",
   "metadata": {},
   "source": [
    "# Train Pole Game on DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d98d92e2-ee96-4450-9ef9-417273e5d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{os.sys.executable} -m pip install gymnasium\n",
    "# !{os.sys.executable} -m pip install Pillow\n",
    "# !{os.sys.executable} -m pip install ipython\n",
    "# !{os.sys.executable} -m pip install pygame\n",
    "# !{os.sys.executable} -m pip install torchsummary\n",
    "# !{os.sys.executable} -m pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d0428c8-4392-40b9-b718-dbd70f050795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful packages\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gymnasium as gym\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "from DQN_Model import DQN\n",
    "from DQN_Model_improved import DQN_improved\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from collections import namedtuple, deque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b123673-94c5-4912-bfc7-45fa78020790",
   "metadata": {},
   "source": [
    "## Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62256990-25eb-4742-9144-dffc10f80a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'CartPole-v1'\n",
    "gamma = 0.99\n",
    "batch_size = 32\n",
    "lr = 0.0001 #1lr = 0.0001\n",
    "initial_exploration = 1000\n",
    "goal_score = 200\n",
    "log_interval = 1 # 10\n",
    "update_target = 100\n",
    "replay_memory_capacity = 1000\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b073d19-c92b-43df-a449-87c216d727a8",
   "metadata": {},
   "source": [
    "## Memory Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fa4c110-558c-42ea-a7d7-ab205a1f4f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple(\n",
    "    'Transition', ('state', 'next_state', 'action', 'reward', 'mask')\n",
    ")\n",
    "Transition_Biased = namedtuple(\n",
    "    'Transition', ('state', 'next_state', 'action', 'reward', 'mask', 'weight')\n",
    ")\n",
    "\n",
    "class Memory_DQN(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque(maxlen=capacity)\n",
    "        self.capacity = capacity\n",
    "\n",
    "    def push(self, state, next_state, action, reward, mask):\n",
    "        self.memory.append(Transition(state, next_state, action, reward, mask))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        transitions = random.sample(self.memory, batch_size)\n",
    "        batch = Transition(*zip(*transitions))\n",
    "        return batch\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "class Memory_DQN_biased(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque(maxlen=capacity)\n",
    "        self.capacity = capacity\n",
    "        self.weights = np.ones(capacity)\n",
    "        self.idx = 0\n",
    "\n",
    "    def push(self, state, next_state, action, reward, mask):\n",
    "        weight = 1.0  # Initial weight for the new sample\n",
    "        self.memory.append(Transition_Biased(state, next_state, action, reward, mask, weight))\n",
    "        self.weights[self.idx] = weight\n",
    "        self.idx = (self.idx + 1) % self.capacity\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        weights = self.weights / np.sum(self.weights)  # Normalize weights\n",
    "        indices = np.random.choice(len(self.memory), batch_size, p=weights)\n",
    "        batch = [self.memory[i] for i in indices]\n",
    "        \n",
    "        # Update weights based on the chosen samples\n",
    "        self.weights[indices] = [self.memory[i].weight for i in indices]\n",
    "        \n",
    "        batch = Transition_Biased(*zip(*batch))\n",
    "        return batch\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0109539-2a4c-450c-9a4c-587e05f44a19",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdc75096-c622-4edf-bb88-0d1d56e07eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(state, target_net, epsilon, env):\n",
    "    if np.random.rand() <= epsilon:\n",
    "        return env.action_space.sample() #random action\n",
    "    else:\n",
    "        return target_net.get_action(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa57b65a-9d6e-4fab-a22b-54f83d605b36",
   "metadata": {},
   "source": [
    "## Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a25c4c30-7454-4797-b6e0-37a54ed2e3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_size 4\n",
      "action_size 2\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1              [-1, 32, 128]             640\n",
      "            Linear-2                [-1, 32, 2]             258\n",
      "================================================================\n",
      "Total params: 898\n",
      "Trainable params: 898\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.03\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.04\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "env=gym.make(env_name)\n",
    "\n",
    "\n",
    "state_size = env.observation_space.low.size\n",
    "action_size = env.action_space.n\n",
    "\n",
    "print(\"state_size\", state_size)\n",
    "print(\"action_size\", action_size)\n",
    "\n",
    "online_net = DQN(state_size, action_size).to(device)\n",
    "target_net = DQN(state_size, action_size).to(device)\n",
    "\n",
    "\n",
    "online_net.train()\n",
    "target_net.train()\n",
    "writer = SummaryWriter('logs')\n",
    "\n",
    "summary(online_net, input_size = (batch_size, state_size)) \n",
    "\n",
    "optimizer = optim.Adam(online_net.parameters(), lr=lr)\n",
    "N_EPISODES = 5000 # 5000\n",
    "\n",
    "#initialize running variables\n",
    "running_score = 0\n",
    "epsilon = 1.0\n",
    "epsilon_decay_rate = 0.000005 #0.000005\n",
    "steps = 0\n",
    "loss = 0\n",
    "\n",
    "# initialize the memory bank\n",
    "memory = Memory_DQN(replay_memory_capacity)\n",
    "# memory = Memory_DQN_biased(replay_memory_capacity)\n",
    "\n",
    "# Before training\n",
    "loss_record = []\n",
    "scores_record = []\n",
    "best_score = float('-inf')  # Initialize best_score with negative infinity\n",
    "best_online_net_weights = None\n",
    "best_target_net_weights = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a60eeb46-7193-4164-a374-de8a3760f1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 episode | score: 17.24 | loss: 1.21893 | epsilon: 1.00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ns/hfpwj42x3zd2qyh387_9zcvm0000gn/T/ipykernel_4645/4081513404.py:42: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  actions = torch.Tensor(batch.action).float().to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759 episode | score: 20.81 | loss: 3.52875 | epsilon: 0.922"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for episode in range(N_EPISODES):\n",
    "    done = False\n",
    "\n",
    "    score = 0\n",
    "    state = env.reset()[0]\n",
    "    state = torch.Tensor(state).to(device)\n",
    "\n",
    "    while not done:\n",
    "        steps += 1\n",
    "        action = get_action(state, target_net, epsilon, env)\n",
    "        \n",
    "        # next_state, reward, done, _, _ = env.step(action) # 5 outputs\n",
    "        next_state, reward, terminated, truncated,_ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        \n",
    "        next_state = torch.Tensor(next_state).to(device)\n",
    "\n",
    "        mask = 0 if done else 1 #don't know what this line does\n",
    "\n",
    "        # i assume this is the penalty function?\n",
    "        reward = reward if not done or score == 499 else -1\n",
    "\n",
    "        action_one_hot = np.zeros(action_size)\n",
    "        action_one_hot[action] = 1\n",
    "\n",
    "        # add to memory bank\n",
    "        memory.push(state, next_state, action_one_hot, reward, mask)\n",
    "\n",
    "        score += reward\n",
    "        state = next_state\n",
    "\n",
    "        if steps > initial_exploration:\n",
    "            epsilon -= epsilon_decay_rate\n",
    "            epsilon = max(epsilon, 0.01)\n",
    "\n",
    "            # process the batch\n",
    "            batch = memory.sample(batch_size)\n",
    "            # print(\"batch\", batch)\n",
    "            states = torch.stack(batch.state).to(device)\n",
    "            next_states = torch.stack(batch.next_state).to(device)\n",
    "            actions = torch.Tensor(batch.action).float().to(device)\n",
    "            rewards = torch.Tensor(batch.reward).to(device)\n",
    "            masks = torch.Tensor(batch.mask).to(device)\n",
    "\n",
    "            q_values = online_net(states).gather(1, actions.long())\n",
    "            # next_q_values = target_net(next_states).max(1)[0]#.detach()\n",
    "            next_q_values = target_net(next_states)#.detach()\n",
    "            # print(\"next_q_values\", next_q_values.shape)\n",
    "            # print(\"masks\", masks.shape, masks)\n",
    "            \n",
    "            masks_broadcasted = masks.unsqueeze(1)  # Shape [32, 1]\n",
    "            duplicated_rewards = rewards.unsqueeze(1).repeat(1, action_size)\n",
    "            \n",
    "            q_target  = duplicated_rewards + gamma * next_q_values*masks_broadcasted\n",
    "            # print(\"q_target\", q_target.shape, q_target)\n",
    "            # print(\"q_values\", q_values.shape, q_values)\n",
    "            # break\n",
    "\n",
    "            \n",
    "            loss = F.mse_loss(q_values, q_target)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if steps % initial_exploration:\n",
    "                target_net.load_state_dict(online_net.state_dict())\n",
    "    score = score if score == 500.0 else score + 1\n",
    "    if running_score == 0:\n",
    "        running_score = score\n",
    "    else:\n",
    "        running_score = 0.99 * running_score + 0.01 * score\n",
    "\n",
    "    scores_record.append(running_score)\n",
    "    loss_record.append(loss)\n",
    "\n",
    "     # Update best_score and store best model weights in memory\n",
    "    if running_score > best_score:\n",
    "        best_score = running_score\n",
    "        best_online_net_weights = online_net.state_dict()\n",
    "        best_target_net_weights = target_net.state_dict()\n",
    "    \n",
    "    if episode % log_interval == 0:\n",
    "        print('\\r{} episode | score: {:.2f} | loss: {:.5f} | epsilon: {:.2f}'.format(\n",
    "            episode, running_score, loss, epsilon), end='')\n",
    "        writer.add_scalar('log/score', float(running_score), episode) # i don't know what this does\n",
    "        writer.add_scalar('log/loss', float(loss), episode)    \n",
    "\n",
    "    if running_score > goal_score:\n",
    "        break\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce694860-37e8-4e61-ac25-96ea7135b951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Create the saved_models folder if it doesn't exist\n",
    "if not os.path.exists('saved_models'):\n",
    "    os.makedirs('saved_models')\n",
    "\n",
    "# Generate a unique train_number based on current timestamp\n",
    "train_number = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "train_folder = f'saved_models/train_{train_number}'\n",
    "\n",
    "# Create the train_number subfolder inside saved_models\n",
    "if not os.path.exists(train_folder):\n",
    "    os.makedirs(train_folder)\n",
    "\n",
    "# Save the model to the train_number subfolder\n",
    "torch.save(online_net.state_dict(), f'{train_folder}/online_net.pth')\n",
    "torch.save(target_net.state_dict(), f'{train_folder}/target_net.pth')\n",
    "\n",
    "# Save the best model weights to the train_number subfolder\n",
    "torch.save(best_online_net_weights, f'{train_folder}/best_online_net.pth')\n",
    "torch.save(best_target_net_weights, f'{train_folder}/best_target_net.pth')\n",
    "\n",
    "def convert_to_ints(lst):\n",
    "    return [int(elem.item()) if torch.is_tensor(elem) else int(elem) for elem in lst]\n",
    "\n",
    "# Save scores_record to a file\n",
    "with open(f'{train_folder}/scores_record.json', 'w') as f:\n",
    "    json.dump(scores_record, f)\n",
    "\n",
    "# Save loss_record to a file\n",
    "with open(f'{train_folder}/loss_record.json', 'w') as f:\n",
    "    json.dump(convert_to_ints(loss_record), f)\n",
    "\n",
    "\n",
    "# Plotting the metrics\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot Rewards\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(scores_record)\n",
    "plt.title('Episode Scores')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Scores')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot Losses (assuming you have a list of losses)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(convert_to_ints(loss_record))\n",
    "plt.title('Episode Losses')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the plots to the train_number subfolder\n",
    "plt.savefig(f'{train_folder}/metrics_plot.png')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59c52ab-0465-4c12-84e0-64d9a390bf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define the path to the JSON files\n",
    "scores_file = f'{train_folder}/scores_record.json'\n",
    "loss_file = f'{train_folder}/loss_record.json'\n",
    "\n",
    "# Load scores_record from the JSON file\n",
    "with open(scores_file, 'r') as f:\n",
    "    loaded_scores_record = json.load(f)\n",
    "\n",
    "# Load loss_record from the JSON file\n",
    "with open(loss_file, 'r') as f:\n",
    "    loaded_loss_record = json.load(f)\n",
    "\n",
    "# Now, loaded_scores_record and loaded_loss_record contain the data from the JSON files\n",
    "print(\"Scores:\", len(loaded_scores_record))\n",
    "print(\"Losses:\", len(loaded_loss_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347297d7-6d7a-48c1-bc6d-6bfea8e49d50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
