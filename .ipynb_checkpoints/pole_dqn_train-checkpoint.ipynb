{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7856b461-e203-4cd9-af6d-9ed7313fc0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: parse error near `-m'\n",
      "zsh:1: parse error near `-m'\n",
      "zsh:1: parse error near `-m'\n",
      "zsh:1: parse error near `-m'\n",
      "zsh:1: parse error near `-m'\n",
      "zsh:1: parse error near `-m'\n"
     ]
    }
   ],
   "source": [
    "!{os.sys.executable} -m pip install gymnasium\n",
    "!{os.sys.executable} -m pip install Pillow\n",
    "!{os.sys.executable} -m pip install ipython\n",
    "!{os.sys.executable} -m pip install pygame\n",
    "!{os.sys.executable} -m pip install torchsummary\n",
    "!{os.sys.executable} -m pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d0428c8-4392-40b9-b718-dbd70f050795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful packages\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gymnasium as gym\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "from DQN_Model import DQN\n",
    "from DQN_Model_improved import DQN_improved\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from collections import namedtuple, deque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b123673-94c5-4912-bfc7-45fa78020790",
   "metadata": {},
   "source": [
    "## Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62256990-25eb-4742-9144-dffc10f80a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'CartPole-v1'\n",
    "gamma = 0.99\n",
    "batch_size = 32\n",
    "lr = 0.0001\n",
    "initial_exploration = 1000\n",
    "goal_score = 200\n",
    "log_interval = 1 # 10\n",
    "update_target = 100\n",
    "replay_memory_capacity = 1000\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b073d19-c92b-43df-a449-87c216d727a8",
   "metadata": {},
   "source": [
    "## Memory Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fa4c110-558c-42ea-a7d7-ab205a1f4f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple(\n",
    "    'Transition', ('state', 'next_state', 'action', 'reward', 'mask')\n",
    ")\n",
    "\n",
    "class Memory_DQN(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque(maxlen=capacity)\n",
    "        self.capacity = capacity\n",
    "\n",
    "    def push(self, state, next_state, action, reward, mask):\n",
    "        self.memory.append(Transition(state, next_state, action, reward, mask))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        transitions = random.sample(self.memory, batch_size)\n",
    "        batch = Transition(*zip(*transitions))\n",
    "        return batch\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0109539-2a4c-450c-9a4c-587e05f44a19",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdc75096-c622-4edf-bb88-0d1d56e07eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(state, target_net, epsilon, env):\n",
    "    if np.random.rand() <= epsilon:\n",
    "        return env.action_space.sample() #random action\n",
    "    else:\n",
    "        return target_net.get_action(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa57b65a-9d6e-4fab-a22b-54f83d605b36",
   "metadata": {},
   "source": [
    "## Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a25c4c30-7454-4797-b6e0-37a54ed2e3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_size 4\n",
      "action_size 2\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 32 elements not 256",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m target_net\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     18\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m summary(online_net, input_size \u001b[38;5;241m=\u001b[39m (batch_size, state_size)) \n\u001b[1;32m     22\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(online_net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m     23\u001b[0m N_EPISODES \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torchsummary/torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(register_hook)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# make a forward pass\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m model(\u001b[38;5;241m*\u001b[39mx)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# remove these hooks\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/EECS6892.RL/final_project/eecse6892-spring24-final-project-jsek/DQN_Model_improved.py:36\u001b[0m, in \u001b[0;36mDQN_improved.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Forward pass through the network\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1561\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1559\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1561\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1564\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1565\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1566\u001b[0m     ):\n\u001b[1;32m   1567\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    184\u001b[0m     bn_training,\n\u001b[1;32m    185\u001b[0m     exponential_average_factor,\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps,\n\u001b[1;32m    187\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:2482\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2480\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2482\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m   2483\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled\n\u001b[1;32m   2484\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: running_mean should contain 32 elements not 256"
     ]
    }
   ],
   "source": [
    "env=gym.make(env_name)\n",
    "\n",
    "\n",
    "state_size = env.observation_space.low.size\n",
    "action_size = env.action_space.n\n",
    "\n",
    "print(\"state_size\", state_size)\n",
    "print(\"action_size\", action_size)\n",
    "\n",
    "online_net = DQN(state_size, action_size).to(device)\n",
    "target_net = DQN(state_size, action_size).to(device)\n",
    "# online_net = DQN_improved(state_size, action_size).to(device)\n",
    "# target_net = DQN_improved(state_size, action_size).to(device)\n",
    "\n",
    "\n",
    "online_net.train()\n",
    "target_net.train()\n",
    "writer = SummaryWriter('logs')\n",
    "\n",
    "summary(online_net, input_size = (batch_size, state_size)) \n",
    "\n",
    "optimizer = optim.Adam(online_net.parameters(), lr=lr)\n",
    "N_EPISODES = 5000\n",
    "\n",
    "#initialize running variables\n",
    "running_score = 0\n",
    "epsilon = 1.0\n",
    "epsilon_decay_rate = 0.000005\n",
    "steps = 0\n",
    "loss = 0\n",
    "\n",
    "# initialize the memory bank\n",
    "memory = Memory_DQN(replay_memory_capacity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60eeb46-7193-4164-a374-de8a3760f1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(N_EPISODES):\n",
    "    done = False\n",
    "\n",
    "    score = 0\n",
    "    state = env.reset()[0]\n",
    "    state = torch.Tensor(state).to(device)\n",
    "\n",
    "    while not done:\n",
    "        steps += 1\n",
    "        action = get_action(state, target_net, epsilon, env)\n",
    "        next_state, reward, done, _, _ = env.step(action) # 5 outputs\n",
    "        next_state = torch.Tensor(next_state).to(device)\n",
    "\n",
    "        mask = 0 if done else 1 #don't know what this line does\n",
    "\n",
    "        # i assume this is the penalty function?\n",
    "        reward = reward if not done or score == 499 else -1\n",
    "\n",
    "        action_one_hot = np.zeros(2)\n",
    "        action_one_hot[action] = 1\n",
    "\n",
    "        # add to memory bank\n",
    "        memory.push(state, next_state, action_one_hot, reward, mask)\n",
    "\n",
    "        score += reward\n",
    "        state = next_state\n",
    "\n",
    "        if steps > initial_exploration:\n",
    "            epsilon -= epsilon_decay_rate\n",
    "            epsilon = max(epsilon, 0.01)\n",
    "\n",
    "            # process the batch\n",
    "            batch = memory.sample(batch_size)\n",
    "            # print(\"batch\", batch)\n",
    "            states = torch.stack(batch.state).to(device)\n",
    "            next_states = torch.stack(batch.next_state).to(device)\n",
    "            actions = torch.Tensor(batch.action).float().to(device)\n",
    "            rewards = torch.Tensor(batch.reward).to(device)\n",
    "            masks = torch.Tensor(batch.mask).to(device)\n",
    "\n",
    "            q_values = online_net(states).gather(1, actions.long())\n",
    "            next_q_values = target_net(next_states).max(1)[0].detach()\n",
    "\n",
    "            q_target  = rewards + gamma * next_q_values*masks\n",
    "            \n",
    "\n",
    "            \n",
    "            loss = F.mse_loss(q_values, q_target.unsqueeze(1))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if steps % initial_exploration:\n",
    "                target_net.load_state_dict(online_net.state_dict())\n",
    "    score = score if score == 500.0 else score + 1\n",
    "    if running_score == 0:\n",
    "        running_score = score\n",
    "    else:\n",
    "        running_score = 0.99 * running_score + 0.01 * score\n",
    "    if episode % log_interval == 0:\n",
    "        print('{} episode | score: {:.2f} | loss: {:.5f} | epsilon: {:.2f}'.format(\n",
    "            episode, running_score, loss, epsilon))\n",
    "        writer.add_scalar('log/score', float(running_score), episode)\n",
    "        writer.add_scalar('log/loss', float(loss), episode)\n",
    "\n",
    "    if running_score > goal_score:\n",
    "        break\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce694860-37e8-4e61-ac25-96ea7135b951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract metrics from memory.memory\n",
    "rewards = [transition.reward for transition in memory.memory]\n",
    "losses = []  # You should collect and store the losses during training to plot them\n",
    "epsilons = []  # You should collect and store the epsilons during training to plot them\n",
    "\n",
    "# Plotting the metrics\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot Rewards\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(rewards)\n",
    "plt.title('Episode Rewards')\n",
    "plt.xlabel('Transition')\n",
    "plt.ylabel('Reward')\n",
    "\n",
    "# Plot Losses (assuming you have a list of losses)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(losses)\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Plot Epsilons (assuming you have a list of epsilons)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(epsilons)\n",
    "plt.title('Epsilon Decay')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Epsilon')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b8d03f-e12b-4666-b95e-d8f98c537f11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
