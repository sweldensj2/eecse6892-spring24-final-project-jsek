{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a4d3b2a",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d7e51b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# !{os.sys.executable} -m pip install gymnasium\n",
    "# !{os.sys.executable} -m pip install Pillow\n",
    "# !{os.sys.executable} -m pip install ipython\n",
    "# !{os.sys.executable} -m pip install pygame\n",
    "# !{os.sys.executable} -m pip install torchinfo \n",
    "# !{os.sys.executable} -m pip install tensorboardX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5ed124",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "706aa66e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import gymnasium as gym\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "\n",
    "from DTQN_Model import DTQN\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from collections import namedtuple, deque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dc3b75",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "306c7d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "env_name = 'CartPole-v1'\n",
    "gamma = 0.99\n",
    "batch_size = 32\n",
    "lr = 0.0001 #1lr = 0.0001\n",
    "initial_exploration = 1000\n",
    "goal_score = 200\n",
    "log_interval = 1 # 10\n",
    "update_target = 100\n",
    "replay_memory_capacity = 1000\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf4bb30",
   "metadata": {},
   "source": [
    "## Memory Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6fedbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple(\n",
    "    'Transition', ('state', 'next_state', 'action', 'reward', 'mask')\n",
    ")\n",
    "\n",
    "class Memory_DTQN(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque(maxlen=capacity)\n",
    "        self.capacity = capacity\n",
    "\n",
    "    def push(self, state, next_state, action, reward, mask):\n",
    "        self.memory.append(Transition(state, next_state, action, reward, mask))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        transitions = random.sample(self.memory, batch_size)\n",
    "        batch = Transition(*zip(*transitions))\n",
    "        return batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f59d19",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bbfbc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(state, target_net, epsilon, env):\n",
    "    if np.random.rand() <= epsilon:\n",
    "        return env.action_space.sample() #random action\n",
    "    else:\n",
    "        return target_net.get_action(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85de02ef",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14c9021b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state size: 4\n",
      "action size: 2\n",
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "DTQN                                          [32, 2]                   281,152\n",
      "├─Linear: 1-1                                 [32, 64]                  320\n",
      "├─TransformerEncoder: 1-2                     [32, 64]                  --\n",
      "│    └─ModuleList: 2-1                        --                        --\n",
      "│    │    └─TransformerEncoderLayer: 3-1      [32, 64]                  281,152\n",
      "│    │    └─TransformerEncoderLayer: 3-2      [32, 64]                  281,152\n",
      "│    │    └─TransformerEncoderLayer: 3-3      [32, 64]                  281,152\n",
      "├─Linear: 1-3                                 [32, 32]                  2,080\n",
      "├─Linear: 1-4                                 [32, 2]                   66\n",
      "===============================================================================================\n",
      "Total params: 1,127,074\n",
      "Trainable params: 1,127,074\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 25.47\n",
      "===============================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.75\n",
      "Params size (MB): 3.18\n",
      "Estimated Total Size (MB): 4.93\n",
      "===============================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evank\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "env=gym.make(env_name)\n",
    "\n",
    "state_size = env.observation_space.low.size\n",
    "action_size = env.action_space.n\n",
    "\n",
    "print(\"state size:\", state_size)\n",
    "print(\"action size:\", action_size)\n",
    "\n",
    "online_net = DTQN(state_size, action_size).to(device)\n",
    "target_net = DTQN(state_size, action_size).to(device)\n",
    "\n",
    "online_net.train()\n",
    "target_net.train()\n",
    "writer = SummaryWriter('logs')\n",
    "\n",
    "print(summary(online_net, input_size=(batch_size, state_size))) \n",
    "\n",
    "optimizer = optim.Adam(online_net.parameters(), lr=lr)\n",
    "N_EPISODES = 10000\n",
    "\n",
    "#initialize running variables\n",
    "running_score = 0\n",
    "epsilon = 1.0\n",
    "epsilon_decay_rate = 0.000005 #0.000005\n",
    "steps = 0\n",
    "loss = 0\n",
    "\n",
    "# initialize the memory bank\n",
    "memory = Memory_DTQN(replay_memory_capacity)\n",
    "\n",
    "# Before training\n",
    "loss_record = []\n",
    "scores_record = []\n",
    "best_score = float('-inf')  # Initialize best_score with negative infinity\n",
    "best_online_net_weights = None\n",
    "best_target_net_weights = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a23b781",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feb4ebfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 episode | score: 13.67 | loss: 0.00000 | epsilon: 1.00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evank\\AppData\\Local\\Temp\\ipykernel_2456\\2106214493.py:41: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:278.)\n",
      "  actions = torch.Tensor(batch.action).float().to(device)\n",
      "C:\\Users\\evank\\AppData\\Local\\Temp\\ipykernel_2456\\2106214493.py:52: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(q_values, q_target.unsqueeze(1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999 episode | score: 24.88 | loss: 18.23347 | epsilon: 0.01"
     ]
    }
   ],
   "source": [
    "for episode in range(N_EPISODES):\n",
    "    done = False\n",
    "\n",
    "    score = 0\n",
    "    state = env.reset()[0]\n",
    "    state = torch.Tensor(state).to(device)\n",
    "\n",
    "    while not done:\n",
    "        steps += 1\n",
    "        action = get_action(state, target_net, epsilon, env)\n",
    "        \n",
    "        # next_state, reward, done, _, _ = env.step(action) # 5 outputs\n",
    "        next_state, reward, terminated, truncated,_ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        \n",
    "        next_state = torch.Tensor(next_state).to(device)\n",
    "\n",
    "        mask = 0 if done else 1 #don't know what this line does\n",
    "\n",
    "        # i assume this is the penalty function?\n",
    "        reward = reward if not done or score == 499 else -1\n",
    "\n",
    "        action_one_hot = np.zeros(2)\n",
    "        action_one_hot[action] = 1\n",
    "\n",
    "        # add to memory bank\n",
    "        memory.push(state, next_state, action_one_hot, reward, mask)\n",
    "\n",
    "        score += reward\n",
    "        state = next_state\n",
    "\n",
    "        if steps > initial_exploration:\n",
    "            epsilon -= epsilon_decay_rate\n",
    "            epsilon = max(epsilon, 0.01)\n",
    "\n",
    "            # process the batch\n",
    "            batch = memory.sample(batch_size)\n",
    "            # print(\"batch\", batch)\n",
    "            states = torch.stack(batch.state).to(device)\n",
    "            next_states = torch.stack(batch.next_state).to(device)\n",
    "            actions = torch.Tensor(batch.action).float().to(device)\n",
    "            rewards = torch.Tensor(batch.reward).to(device)\n",
    "            masks = torch.Tensor(batch.mask).to(device)\n",
    "\n",
    "            q_values = online_net(states).gather(1, actions.long())\n",
    "            next_q_values = target_net(next_states).max(1)[0].detach()\n",
    "\n",
    "            q_target  = rewards + gamma * next_q_values*masks\n",
    "            \n",
    "\n",
    "            \n",
    "            loss = F.mse_loss(q_values, q_target.unsqueeze(1))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if steps % initial_exploration:\n",
    "                target_net.load_state_dict(online_net.state_dict())\n",
    "    score = score if score == 500.0 else score + 1\n",
    "    if running_score == 0:\n",
    "        running_score = score\n",
    "    else:\n",
    "        running_score = 0.99 * running_score + 0.01 * score\n",
    "\n",
    "    scores_record.append(running_score)\n",
    "    loss_record.append(loss)\n",
    "\n",
    "     # Update best_score and store best model weights in memory\n",
    "    if running_score > best_score:\n",
    "        best_score = running_score\n",
    "        best_online_net_weights = online_net.state_dict()\n",
    "        best_target_net_weights = target_net.state_dict()\n",
    "    \n",
    "    if episode % log_interval == 0:\n",
    "        print('\\r{} episode | score: {:.2f} | loss: {:.5f} | epsilon: {:.2f}'.format(\n",
    "            episode, running_score, loss, epsilon), end='')\n",
    "        writer.add_scalar('log/score', float(running_score), episode) # i don't know what this does\n",
    "        writer.add_scalar('log/loss', float(loss), episode)    \n",
    "\n",
    "    if running_score > goal_score:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45309964",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65b603c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the saved_models folder if it doesn't exist\n",
    "if not os.path.exists('saved_models/DTQN'):\n",
    "    os.makedirs('saved_models/DTQN')\n",
    "\n",
    "# Generate a unique train_number based on current timestamp\n",
    "train_number = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "train_folder = f'saved_models/DTQN/train_{train_number}'\n",
    "\n",
    "# Create the train_number subfolder inside saved_models\n",
    "if not os.path.exists(train_folder):\n",
    "    os.makedirs(train_folder)\n",
    "\n",
    "# Save the model to the train_number subfolder\n",
    "torch.save(online_net.state_dict(), f'{train_folder}/online_net.pth')\n",
    "torch.save(target_net.state_dict(), f'{train_folder}/target_net.pth')\n",
    "\n",
    "# Save the best model weights to the train_number subfolder\n",
    "torch.save(best_online_net_weights, f'{train_folder}/best_online_net.pth')\n",
    "torch.save(best_target_net_weights, f'{train_folder}/best_target_net.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dbfb99",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421a4376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_ints(lst):\n",
    "    return [int(elem.item()) if torch.is_tensor(elem) else int(elem) for elem in lst]\n",
    "\n",
    "# Plotting the metrics\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot Rewards\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(scores_record)\n",
    "plt.title('Episode Scores')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Scores')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot Losses (assuming you have a list of losses)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(convert_to_ints(loss_record))\n",
    "plt.title('Episode Losses')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the plots to the train_number subfolder\n",
    "plt.savefig(f'{train_folder}/metrics_plot.png')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
